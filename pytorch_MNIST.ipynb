{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# A run through of using PyTorch to create a simple NN to classify MNIST data \n",
                "\n",
                "Imports"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import DataLoader\n",
                "import torchvision.datasets as datasets\n",
                "import torchvision.transforms as transforms"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Creating very simple fully connected network"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "source": [
                "class NN(nn.Module):\n",
                "    def __init__(self, input_size, num_classes):\n",
                "        super(NN, self).__init__()\n",
                "        self.fc1 = nn.Linear(input_size, 50) # input layer\n",
                "        self.fc2 = nn.Linear(50, num_classes) # output layer\n",
                "    \n",
                "    def forward(self, x):\n",
                "        x = F.relu(self.fc1(x))\n",
                "        x = self.fc2(x)\n",
                "        return x"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Set device\n"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "source": [
                "device = torch.device('cpu')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "hyperparameters"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "source": [
                "input_size = 784\n",
                "num_classes = 10\n",
                "learning_rate = 0.001\n",
                "batch_size = 64\n",
                "num_epochs = 1"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Load Data"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "source": [
                "train_dataset = datasets.MNIST(root='dataset/', train=True, transform=transforms.ToTensor(), download=True)\n",
                "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
                "\n",
                "test_dataset = datasets.MNIST(root='dataset/', train=False, transform=transforms.ToTensor(), download=True)\n",
                "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
                        "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "100.0%\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Extracting dataset/MNIST/raw/train-images-idx3-ubyte.gz to dataset/MNIST/raw\n",
                        "\n",
                        "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
                        "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "102.8%\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Extracting dataset/MNIST/raw/train-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
                        "\n",
                        "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
                        "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "100.0%\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Extracting dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw\n",
                        "\n",
                        "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
                        "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "112.7%"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Extracting dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw\n",
                        "\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "\n",
                        "/home/groth/.conda/envs/pytorch/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448222085/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
                        "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Initialize network"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "source": [
                "model = NN(input_size=input_size, num_classes=num_classes).to(device)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "Loss and optimizer"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "source": [
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "train network"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "source": [
                "for epoch in range(num_epochs):\n",
                "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
                "        # get data to device\n",
                "        data = data.to(device=device)\n",
                "        targets = targets.to(device=device)\n",
                "\n",
                "        # get data to correct shape\n",
                "        data = data.reshape(data.shape[0], -1)\n",
                "\n",
                "        # forward\n",
                "        scores = model(data)\n",
                "        loss = criterion(scores, targets)\n",
                "\n",
                "        # backward\n",
                "        optimizer.zero_grad()\n",
                "        loss.backward()\n",
                "\n",
                "        # optimizer step\n",
                "        optimizer.step()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "check accuracy on training and test to evaluate model"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "source": [
                "def check_accuracy(loader, model):\n",
                "    if loader.dataset.train:\n",
                "        print(\"Checking accuracy on training data\")\n",
                "    else:\n",
                "        print(\"Checking accuracy on test data\")\n",
                "    num_correct = 0\n",
                "    num_samples = 0\n",
                "    model.eval()\n",
                "\n",
                "    with torch.no_grad():\n",
                "        for x,y in loader:\n",
                "            x = x.to(device=device)\n",
                "            y = y.to(device=device)\n",
                "            x = x.reshape(x.shape[0], -1)\n",
                "\n",
                "            scores = model(x)\n",
                "            _, predictions = scores.max(1)\n",
                "            num_correct += (predictions == y).sum()\n",
                "            num_samples += predictions.size(0)\n",
                "        \n",
                "        print(f'Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n",
                "\n",
                "    model.train()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "source": [
                "check_accuracy(train_loader, model)\n",
                "check_accuracy(test_loader, model)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Checking accuracy on training data\n",
                        "Got 55603 / 60000 with accuracy 92.67\n",
                        "Checking accuracy on test data\n",
                        "Got 9289 / 10000 with accuracy 92.89\n"
                    ]
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.6 64-bit ('pytorch': conda)"
        },
        "interpreter": {
            "hash": "541542026112d83b9c98e86310731b53a3e720c97c121ed9b4dd02e831f62f4a"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}